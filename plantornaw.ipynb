{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_dir_path': '/Users/jadeevans/Documents/Code/machine_learning_data/plant_data'}\n"
     ]
    }
   ],
   "source": [
    "from os import getenv\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "config = {\n",
    "    \"DATA_DIR_PATH\": os.getenv(\"DATA_DIR_PATH\"),\n",
    "    \"SAVE_TORCH_DIR_PATH\": os.getenv(\"SAVE_TORCH_DIR_PATH\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# torch.utils.data is a PyTorch method for importing data\n",
    "from torch.utils.data import Dataset, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import aggregate_xml_data as ml_helpers\n",
    "from PIL import Image, ImageMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pandas import read_xml\n",
    "\n",
    "\n",
    "#this class is probably just holding a dataframe\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, data_dir, data_label_filepath, transform=None, target_transform=None):\n",
    "        self.img_labels = read_xml(data_label_filepath, xpath=\"//Data//Image\")\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_filename = self.img_labels.iloc[idx, 0]\n",
    "        #idx 12 is the <content-mapping> tag\n",
    "        img_dir = self.img_labels.iloc[idx, 11]\n",
    "        img_path = f'{img_dir}/{img_filename}'\n",
    "        absolute_img_path = os.path.join(self.data_dir, img_path)\n",
    "\n",
    "        image = Image.open(absolute_img_path)\n",
    "        #change label index here (0 is filename)\n",
    "        label = self.img_labels.iloc[idx, 12]\n",
    "        # label = {\n",
    "        #     \"filename\": self.img_labels.iloc[idx, 0],\n",
    "        #     \"name\": self.img_labels.iloc[idx, 1],\n",
    "        #     \"author\": self.img_labels.iloc[idx, 3]\n",
    "        # }\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform all images, define full dataset, split full set into test and train, load test/train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose, Resize, CenterCrop, Grayscale, ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "import aggregate_xml_data as ml_helpers\n",
    "\n",
    "\n",
    "train_transform = Compose([Grayscale(num_output_channels=1),Resize(224), CenterCrop(224), ToTensor()]) \n",
    "## changed size from 28 (model trained on this size) to 224 to check reversion to pic from tensor\n",
    "\n",
    "\n",
    "target_transform = int\n",
    "# target_transform = Compose([Resize(255), ToTensor()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jadeevans/Documents/Code/machine_learning_data/plant_data\n"
     ]
    }
   ],
   "source": [
    "# BUILD label file\n",
    "# training_data = ImageFolder(root=\"plant_data\", transform=transform)\n",
    "# target_data = ImageFolder(root=\"plant_data\", target_transform=target_transform)\n",
    "data_dir = config[\"DATA_DIR_PATH\"]\n",
    "data_label_file = \"plant_labels.xml\"\n",
    "image_labels_filepath = ml_helpers.aggregate_xml_data(data_dir, data_label_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_labels_filepath' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/jadeevans/Documents/Code/Plants/plantornaw.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jadeevans/Documents/Code/Plants/plantornaw.ipynb#ch0000031?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(image_labels_filepath)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_labels_filepath' is not defined"
     ]
    }
   ],
   "source": [
    "print(image_labels_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the length of the full data set: 143101\n",
      "<torch.utils.data.dataset.Subset object at 0x149a56560>\n",
      "<torch.utils.data.dataset.Subset object at 0x149a57cd0>\n",
      "<torch.utils.data.dataset.Subset object at 0x149ab7f40>\n",
      "==============================\n",
      "Train data set: 114480\n",
      "Test data set: 14310\n",
      "Val data set: 14311\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# DEFINE dataset using custom class in order to try and incorporate label data\n",
    "full_dataset = CustomImageDataset(data_dir, image_labels_filepath, train_transform, target_transform)\n",
    "#SPLIT INTO TEST AND TRAIN SUBSETS\n",
    "\n",
    "print('This is the length of the full data set:', len(full_dataset))\n",
    "\n",
    "train_set_size = int(len(full_dataset) * 0.8)\n",
    "test_set_size = int(len(full_dataset) * 0.1)\n",
    "validation_set_size = int(len(full_dataset))-train_set_size-test_set_size\n",
    "train_set, test_set, validation_set = random_split(full_dataset, [train_set_size, test_set_size, validation_set_size])\n",
    "print(train_set)\n",
    "print(test_set)\n",
    "print(validation_set)\n",
    "   \n",
    "# After\n",
    "print('='*30)\n",
    "print('Train data set:', len(train_set))\n",
    "print('Test data set:', len(test_set))\n",
    "print('Val data set:', len(validation_set))\n",
    "# loading dataset in data loader\n",
    "#dataloader = DataLoader(dataset=training_data, batch_size=4, shuffle=True)\n",
    "train_dataloader = DataLoader(dataset=train_set, batch_size=100, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_set, batch_size=100, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([100, 1, 224, 224])\n",
      "Labels batch shape: torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "features, label_names = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {features.size()}\")\n",
    "print(f\"Labels batch shape: {label_names.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "#get device for training\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define NN class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(224*224, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make NN instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=50176, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameterize the layers of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=50176, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 50176]) | Values : tensor([[ 0.0031, -0.0013, -0.0003,  ..., -0.0006, -0.0009,  0.0040],\n",
      "        [ 0.0005,  0.0026, -0.0037,  ...,  0.0014, -0.0012, -0.0013]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([ 0.0042, -0.0024], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0365,  0.0160,  0.0422,  ..., -0.0097,  0.0080, -0.0211],\n",
      "        [ 0.0326,  0.0333,  0.0206,  ...,  0.0177,  0.0050, -0.0418]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([ 0.0212, -0.0076], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([3, 512]) | Values : tensor([[ 0.0227, -0.0438, -0.0300,  ...,  0.0380,  0.0220,  0.0036],\n",
      "        [-0.0300, -0.0036,  0.0289,  ...,  0.0177,  0.0111, -0.0070]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([3]) | Values : tensor([-0.0397,  0.0404], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 100\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set optimization loop. (These are just instructions, a dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the loss function and optimizer, and pass it to train_loop and test_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.104653  [    0/114480]\n",
      "loss: 0.917058  [10000/114480]\n",
      "loss: 0.965800  [20000/114480]\n",
      "loss: 0.913943  [30000/114480]\n",
      "loss: 0.942171  [40000/114480]\n",
      "loss: 0.860404  [50000/114480]\n",
      "loss: 0.913270  [60000/114480]\n",
      "loss: 0.798885  [70000/114480]\n",
      "loss: 0.906336  [80000/114480]\n",
      "loss: 0.829192  [90000/114480]\n",
      "loss: 0.944595  [100000/114480]\n",
      "loss: 0.952758  [110000/114480]\n",
      "Test Error: \n",
      " Accuracy: 62.6%, Avg loss: 0.875127 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.900661  [    0/114480]\n",
      "loss: 0.888458  [10000/114480]\n",
      "loss: 0.853463  [20000/114480]\n",
      "loss: 0.891624  [30000/114480]\n",
      "loss: 0.921420  [40000/114480]\n",
      "loss: 0.863468  [50000/114480]\n",
      "loss: 0.909683  [60000/114480]\n",
      "loss: 0.843854  [70000/114480]\n",
      "loss: 0.830236  [80000/114480]\n",
      "loss: 0.889433  [90000/114480]\n",
      "loss: 0.917643  [100000/114480]\n",
      "loss: 0.821966  [110000/114480]\n",
      "Test Error: \n",
      " Accuracy: 62.7%, Avg loss: 0.866745 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.842140  [    0/114480]\n",
      "loss: 0.763032  [10000/114480]\n",
      "loss: 0.898685  [20000/114480]\n",
      "loss: 0.914239  [30000/114480]\n",
      "loss: 0.828890  [40000/114480]\n",
      "loss: 0.740177  [50000/114480]\n",
      "loss: 0.841556  [60000/114480]\n",
      "loss: 0.890272  [70000/114480]\n",
      "loss: 0.823308  [80000/114480]\n",
      "loss: 0.880511  [90000/114480]\n",
      "loss: 0.887282  [100000/114480]\n",
      "loss: 0.854705  [110000/114480]\n",
      "Test Error: \n",
      " Accuracy: 63.5%, Avg loss: 0.859572 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.786674  [    0/114480]\n",
      "loss: 0.854831  [10000/114480]\n",
      "loss: 0.872267  [20000/114480]\n",
      "loss: 0.882560  [30000/114480]\n",
      "loss: 0.849937  [40000/114480]\n",
      "loss: 0.864935  [50000/114480]\n",
      "loss: 0.754292  [60000/114480]\n",
      "loss: 0.869550  [70000/114480]\n",
      "loss: 0.953521  [80000/114480]\n",
      "loss: 0.795343  [90000/114480]\n",
      "loss: 0.902356  [100000/114480]\n",
      "loss: 0.847237  [110000/114480]\n",
      "Test Error: \n",
      " Accuracy: 63.6%, Avg loss: 0.855522 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.792479  [    0/114480]\n",
      "loss: 0.917806  [10000/114480]\n",
      "loss: 0.852701  [20000/114480]\n",
      "loss: 0.895324  [30000/114480]\n",
      "loss: 0.834924  [40000/114480]\n",
      "loss: 0.960041  [50000/114480]\n",
      "loss: 0.867348  [60000/114480]\n",
      "loss: 0.853512  [70000/114480]\n",
      "loss: 0.786088  [80000/114480]\n",
      "loss: 0.891423  [90000/114480]\n",
      "loss: 0.911649  [100000/114480]\n",
      "loss: 0.769513  [110000/114480]\n",
      "Test Error: \n",
      " Accuracy: 63.8%, Avg loss: 0.852323 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, config[\"SAVE_TORCH_DIR_PATH\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision.transforms import ToPILImage\n",
    "\n",
    "# val_image, val_label = next(iter(validation_set))\n",
    "# post_transform = transforms.Compose([Resize(255), ToPILImage(mode=\"L\")])\n",
    "\n",
    "# final_pic = post_transform(val_image)\n",
    "# final_pic.show()\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     # print({model(val_image)})\n",
    "#     final_pic = post_transform(model(val_image))\n",
    "#     final_pic.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# lmodel = torch.load('<insert-file-path-here>')\n",
    "# val_dataloader = DataLoader(dataset=validation_set, batch_size=3, shuffle=True)\n",
    "# val_img, val_label = next(iter(val_dataloader))\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     prediction = lmodel(val_img)\n",
    "#     pred_label = np.argmax(prediction)\n",
    "\n",
    "# print(pred_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# val_dataloader = DataLoader(dataset=validation_set, batch_size=3, shuffle=True)\n",
    "# val_img, val_label = next(iter(val_dataloader))\n",
    "\n",
    "# # CONTENT_LABEL_MAPPING = {\n",
    "# #     \"0\":\"Leaf\",\n",
    "# #     \"1\":\"Flower\",\n",
    "# #     \"2\":\"Entire\",\n",
    "# # }\n",
    "\n",
    "# print(f\"Feature batch shape: {val_img.size()}\")\n",
    "# print(f\"Labels batch shape: {val_label.size()}\")\n",
    "# look_here = val_img.squeeze()\n",
    "# validation_label = val_label[0]\n",
    "\n",
    "\n",
    "# for i in range(3):\n",
    "#     plt.imshow(val_img[i].squeeze())\n",
    "#     print(f\"Label: {val_label[i]}\")\n",
    "#     plt.show(i+1)\n",
    "#     # plt.imshow(np.transpose(val_image.numpy(), (1, 2, 0)))\n",
    "#     # plt.figure(i+1)\n",
    "# plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (2466260402.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [8]\u001b[0;36m\u001b[0m\n\u001b[0;31m    trained_model = torch.load(config[])\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "#running the imported model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 3\n",
    "trained_model = torch.load(config[\"SAVE_TORCH_DIR_PATH\"])\n",
    "val_dataloader = DataLoader(dataset=validation_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_img, val_label = next(iter(val_dataloader))\n",
    "# print('test', val_img[2])\n",
    "# print('this is it:', val_label.size())\n",
    "# for val_img, val_label in val_dataloader:\n",
    "#     print('this is it:', val_label)\n",
    "\n",
    "with torch.no_grad():\n",
    "    prediction = trained_model(val_img[0])\n",
    "    print('my preds: ', prediction)\n",
    "    pred_label = np.argmax(prediction)\n",
    "    # print('return index at prediction: ', val_img[pred_label])\n",
    "    # pred_label = prediction\n",
    "\n",
    "print(f\"Feature batch shape: {val_img.size()}\")\n",
    "print(f\"Labels batch shape: {val_label.size()}\")\n",
    "print(f\"Predicted Labels batch shape: {pred_label.size()}\")\n",
    "# look_here = val_img.squeeze()\n",
    "# validation_label = val_label[0]\n",
    "\n",
    "\n",
    "for i in range(1):\n",
    "    plt.imshow(val_img[i].squeeze())\n",
    "    print(f\"Label: {val_label[i]}\")\n",
    "    print(val_label.dtype)\n",
    "    # print(f\"Predicted Label: {pred_label.item()}\")\n",
    "    print(f\"Predicted Label: {pred_label}\")\n",
    "    print(pred_label.dtype)\n",
    "    plt.show(i)\n",
    "    # plt.imshow(np.transpose(val_image.numpy(), (1, 2, 0)))\n",
    "    # plt.figure(i+1)\n",
    "# plt.show\n",
    "\n",
    "# plt.imshow(val_img.squeeze())\n",
    "# print(f\"Label: {val_label}\")\n",
    "# print(val_label.dtype)\n",
    "#     # print(f\"Predicted Label: {pred_label.item()}\")\n",
    "# print(f\"Predicted Label: {pred_label}\")\n",
    "# print(pred_label.dtype)\n",
    "#     # plt.imshow(np.transpose(val_image.numpy(), (1, 2, 0)))\n",
    "#     # plt.figure(i+1)\n",
    "# plt.show\n",
    "\n",
    "val_label == pred_label"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
